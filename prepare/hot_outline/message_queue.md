# 消息队列与分布式（更多面试问题，欢迎关注微信公众号「帅地玩编程」）

## 消息队列

### 缺点

- 更加复杂
- 如果消息队列崩了，会导致其他服务都崩了
- 一致性问题：例如A发了条消息，BC都执行，但D没执行

### 又哪些消息队列框架

- RabbitMQ

  - 吞吐量万级别，延迟低，采用erlang语言开发。
  - 非常棒的管理界面，社区比较活跃
  - 功能较完备
  - 不是分布式的

- ActiveMQ

  - 吞吐量较低，万级别，会丢失消息，维护越来越少
  - 技术成熟

- RocketMQ

  - 十万级别，阿里开源
  - 功能完备，阿里开源，品牌保障
  - 官网维护，项目被抛弃的花，就难受了

- kafka

  - 超高吞吐量
  - 功能简单，适合大数据、日志采集等
  - 分布式的
  - 每个partition对应一个消费者

### 优点

- 解耦
- 异步
- 削峰

### 如何保证高可用

- RabbitMQ

  - 普通集群模式

    - 原理

      - 其中一个队列拥有元数据和目标数据，其他队列只有元数据
      - 当消费者来请求消息的时候，其他队列回去拥有数据的队列拿数据，再发给消费者

    - 缺点

      - 队列之间存在大量消息的传递
      - 如果拥有数据的队列挂了就凉了

  - 镜像集群模式

    - 原理

      - 所有队列都拥有一模一样的数据

    - 如何开启？

      - 再管理界面创建镜像的协议，创建队列时指定该协议

### 如何保证消息按照顺序执行

- rabbitmq

  - 原因：一个queue多个消费者导致顺序出错
  - 解决方法：一个queue对应一个消费者，或者消费者内部弄一些内存队列，然后分发给不同层的woker处理

- kafka

  - 原因：虽然一个partition只有一个消费者，但消费者内部多个线程消费，导致不一致
  - 解决方法：

    - 单线程
    - 或者消费者内部维护一些队列，然后不同的key存放道不同的队列，之后让一个线程只负责一个队列

### 如何保证消息不会被重复消费（幂等性）

- 原因：这里有个偏移量的概念，消息者每次消费了之后都会进行提交，用来告诉MQ我消费道哪了，不过提交的时候并不是说消费一条就马上提交，而是消息了一定的量才提交，如果这时候消息了一些还没提交，然后挂了。之后MQ就会重复发这些被消费的数据给它，导致重复消息
- 如何保证幂等性？

  - 写数据的时候，根据主键查一下是否有该数据了，如果有，则只需要更新一下
  - 如果是写redis的字符串，则没事，天然幂等性
  - 每次发消息的时候加一个全局的id，然后消费者每次消费之后存放再redis的set里，每次要消费的时候查询消费过没有。

### 如何保证消息不丢失

- RabbitMQ

  - 再生产者发消息过程中网络丢失了

    - 可以用rabbitmq提供的事物机制来解决了，通过channel.txSelect来开启，不过事务机制是同步的，性能太差
    - 通过消费者自己发送确认，即confirm机制来解决。该函数接收成功会回调发送ack，否则发送nack

  - MQ自己弄丢失了，比如重启

    - 通过持久化来解决
    - 如果还没持久化就挂了，则还是会丢失，所以可以和confirm机制进行配合

  - 消费者弄丢了

    - 关闭自动提交，而是自己来提交，等消息处理完毕再提交

- kafka

  - 消费端弄丢

    - 关闭自动提交即可，当然这会导致消息重复消费，自己保证幂等性即可

  - kafka弄丢了

    - 例如主leader挂了，但是数据还没有同步，此时重新选举follwer为主节点，然后同步数据，导致丢失
    - 方法：只有等leader全部同步成功之后才进行确认

### 消息积压了几千万怎么办

- 先修复现有的consumer，然后停止工作
- 新建一个topic，之后弄10个partition和10个consumer
- 弄一个消息分发程序，把原来的消息分发到10个queue上
- 弄10个消费者来消费这10个queue
- 相当于用了10倍的速度，等消费完之后再恢复到原来的配置

### 消息过期了怎么办

- 不要设置过期时间
- 重新批量导入过期的消息

### MQ写满了怎么办

- 只能丢消息了，一边丢一边记录这些消息，之后等高峰期过了再来补这些数据

### 如何设计一个消息队列

- 支持伸缩性，例如随时扩大容量。这个可以参考kafka的设计理念，弄成分布式的，把消息分成不同的topic，每个topic有多个partition，每个partition由一个队列来消费。之后内存不够了，直接多加几个partition 即可
- 保证数据不丢失，这个时候显然需要持久化
- 保证高可用：这个时候可以采用leader和follwer以及选举机制
- 支持数据领丢失

## 分布式

### 分布式锁

- redis实现分布式锁

  - 大致加锁步骤

    - Set order:1:lock  随机值 nx px 过期时间
    - 如果设置成功，则加锁成功
    - 如果设置失败，则说明有人持有这把锁了，加锁失败，那么则会过段时间再来尝试获取
    - 时间一到，会自动删除锁

  - 解锁步骤

    - 判断该key是否存在，如果不存在，则说明该锁自动删除了
    - 如果存在，判断该value是否与自己相等，如果相等，则删除该key，如果不相等则代表该锁被别人获取了。
    - 解锁由于涉及到比较判断等，所以要用lua脚本来操作redis语句

  - 上面演示的是用单个redis来加锁，实际上单个不安全，而是用多个redis集群的，如果能够在 二分之一以上的redis加锁成功，则获得该锁。并且每次加锁的时候都会计算好超时时间，一般十几毫秒，如果在这段时间没加上锁，则加锁失败

- zk分布式锁

  - 加锁

    - 客户端在该zk上创建零时节点，如果创建成功，则获取该锁，之后其他客户端就是创建锁失败
    - 创建失败的话就会注册一个监听器

  - 解锁

    - 解锁的时候就会删除该节点，该节点被删除之后就会触发监听器
    - 监听器就会告诉客户端，可以继续来获取锁了

  - 不过创建节点存在并发，所以创建节点的时候会带上时间戳，之后对那些节点进行排序，时间最早的获取到锁

- 两种分布式锁对比

  - redis需要自己不断尝试，消耗性能,zk注册了监听器，性能开销少
  - redis如果客户端挂了，只能等待超时才能释放锁，而zk客户端挂了，节点自动删除

### zookeeper有哪些应用

- 分布式锁
- 协调

  - 例如A把消息放进消息队列的时候，给该消息注册一个监听器，B完成了之后对该节点是值进行更新，zk在把该更新的值告诉A

- 高可用

  - 主A创建一个零时节点，A挂了，节点被删除了，zk通知备B，备B顶替上，并且创建一个同名临时节点，值不一样

- 元数据、配置信息管理

### 分布式session

- 可以用redis来管理
- 把session相关操作都交给spring session 来操作

## 分库分表

### 为什么要分库分表

- 单表数据量太大，影响sql性能。一般单表数据只能几百万
- 单裤的话扛不了多高的并发量，分库可以分担压力，并且单裤能够存储的数据量有限
- 可以hash字段分表，也可以按时间范围来分表，各有优缺点

### 有哪些中间件

- Sharding-JDBC

  - 不需要二次转发，不需要代理层

- Mycat

  - 属于代理层

### 如何把单机动态改装成分库分表的

- 一种最简单的方式就是停机拆分了
- 双写迁移方案

  - 进行写的时候，不进写到新库中，同时也写到老的库中，这种就称之为双写了
  - 然后再后天一边用导数工具进行导数。导数据的时候除非数据比新库的新或者新库没有，才进行更新
  - 导完一次之后，可能还会存在数据不一致，这个时候就可以进行一轮校验，如果校验过程中发现不一致则更新。如此往返校验，知道数据一致

### 如何设计一个可以动态扩容的分库分表方案

- 基本设计方法

  - 选择一个中间件
  - 预测好要分几个库，几张表
  - 处理好双写方案

- 优化

  - 由于一个数据库服务器是可以弄多个库的，所以我们可以一开始的时候就多弄几个库几张表，例如32和32。以后想要扩容了，只需要多加一些服务器，然后直接把整个库迁移过来就行了
  - 之后设计好路由规则等

### 如何获取全局ID

- 用一个数据库来自增生产id，不过这种方法性能不高，扛不了很大的并发量，但是操作简单
- 采用UUID，不过这种主键太长，不利于存放，而且弄成索引的时候性能也比较差
- 水平分表的时候，id可以前缀一个序列。
- 获取当前时间，不过如果并发量太高，会出现重复，一般就是用获取到的时间和业务的其他字段拼接起来
- snowflake算法

  - 一共64位
  - 接着41位代表毫秒数，也就是时间戳
  - 接着10位代表机器。
  - 接着12位代表序列，意味着允许1秒内有4068个重复的id，然后有这个序列号来辨认

### 读写分离如何实现

- 一般就是用一个主库写，多个从库读，然后从库把主库的数据同步复制过来
- 复制原理

  - 主库把写操作用binlog存档，之后从库连接数主数据，用一个IO线程把日志拷贝过来
  - 接着把日志写入到一个relay中继日志中，然后开一个线程来写这些日志
  - 存在的问题

    - 由于此时是同步的，所以会存在延时
    - 如果主数据库挂了，就会出现数据丢失

  - 处理方法

    - 采用半同步复制来解决数据丢失问题
    - 采用并行来处理延时问题

  - 半同步复制

    - 就是主库写了数据之后要求强制同步到从库，从库把日志写入relay中继之后，给主库返回一个ack。
    - 然后主库至少要收到一个从库的ack才认为是写入完成

  - 并行复制

    - 所谓并行复制，指的是从库开启多个线程，并行读取 relay log 中不同库的日志，然后并行重放不同库的日志，这是库级别的并行

- 故障案例

  - 插入一条数据，需要马上查询，导致没有查询到
  - 解决方法

    - 多分几个主库来承载压力
    - 重写代码
    - 开启数据库并行复制
    - 如果真的要马上查询，大不了只连主库，不够不推荐
